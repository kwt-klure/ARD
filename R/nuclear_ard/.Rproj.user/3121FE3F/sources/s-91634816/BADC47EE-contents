
#' Accelerated gradient function for ARD
#' 
#' \code{accel_nuclear_gradient} implements the Accelerated Gradient Algorithm (Algorithm 2) 
#' from Ji & Ye (2009). This should be the only function users interact with directly 
#' from the \emph{ardlasso} package.
#' 
#' @param inputs A matrix object. This contains ARD census data in matrix form.
#'  It should be of dimension N x K, where N = village size and K = number of ARD characteristics.
#' @param outputs A matrix object. This contains the ARD survey data 
#'  in matrix form with size M x K, where N > M = number of households receiving ARD questionairre. 
#' @param lambda A scalar (numeric) value. This is an initial guess that will be iterated on.
#' @param iterations A scalar (integer) value. It is the number of iterations the user 
#'  specifies should occur. Set by default to 100.
#' @return A scalar value denoting the value of our loss function. 
#' @export
accel_nuclear_gradient <- function(inputs, outputs, lambda, iterations = 100, initial = 0) {
  # This function implements Algorithm 2 from "An Accelerated Gradient
  # Method for Trace Norm Minimization" by Ji & Ye (2009)
  
  epsilon <- 0.1
  
  # Initialize scalar values
  L       <- 1
  gamma   <- 1
  alpha   <- 1
  

  
  # Initialize W_0 = Z_1 \in R^{m x n}
  k <- dim(inputs)[0] #k is N in Wainwright Negahban (WN)
  m <- dim(inputs)[1] #m is m1 in WN
  n <- dim(outputs)[1] #n is m2 in WN
  if (any(c('Matrix', 'dgCMatrix') %in% class(initial)) & dim(initial) == c(m, n)) {
    Z <- initial
  } else {
    Z <- runif(m * n, min = -99999, max = 99999) %>% 
          matrix(nrow = m, ncol = n)
  } 
  
  
  for (i in 1:iterations) {
    # Step 1 of iteration: Must initialize L bar by setting to L_{k - 1}
    L.bar <- L

    # Update W
    W <- next_W_func(inputs, outputs, lambda, L, Z)
    
    # Step 2: While loop only activated if 
    # F(p_L(Z_{k - 1})) > Q(p_L(Z_{k-1}), Z_{k-1}).
    # Removing \lambda ||W||_* from both sides since cancels out, 
    # nuclear norm computation isn't super efficient, and don't
    # calculate F or Q elsewhere, so don't need generality.
    # Effectively, this clause says only keep iterating if actual
    # loss value is still greater than approximated loss, because
    # that means we can do better by iterating on the value of L.
    F.value <- obj_func(inputs, outputs, W)
    Q.value <- obj_func.approx(inputs, outputs, Z, W, mu)
    while (F.value > Q.value) {
      # Update L bar, as stated in algorithm.
      L.bar <- gamma * L.bar
      
      # Recalculate values for while loop check.
      W     <- next_W_func(inputs, outputs, lambda, L.bar, Z)
      F.value <- obj_func(inputs, outputs, W)
      Q.value <- obj_func.approx(inputs, outputs, Z, W, mu)
    }

    # Step 3: Update values before next iteration. 
    L           <- L.bar
    W_kmin1     <- Z
    alpha_kmin1 <- alpha
    alpha       <- (1 + sqrt(1 + 4*alpha^2))/2
    Z           <- W + ((alpha - 1)/alpha)*(W - W_kmin1)
    
  }
  

  
  return(W)
}