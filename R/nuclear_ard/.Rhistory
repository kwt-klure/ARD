MSE_LSM <- mean((P_LSM.hat - P_LSM)^2)
source('~/Dropbox/ARD/HossGridSearch/monte_carlo_local.R')
source('~/Dropbox/ARD/HossGridSearch/monte_carlo_local.R')
traceback()
R <- 2
simulation_outputs <- mclapply(1:R, function(x) MSE_simulation(x, lambda), mc.cores = num_cores)
simulation_outputs
simulation_outputs$MSE_LSM
MSE_simulation <- function(sim_number, lambda) {
# First, we conduct the simulation for the latent space model.
alpha        <- rnorm(N) # Generate intercept term.
positions    <- matrix(rexp(N * 2), nrow=N, ncol=2) # Generate locations.
latent_index <- alpha + t(replicate(N, alpha)) - pdist(positions) # Compute latent index.
P_LSM        <- exp(latent_index) / (1 + exp(latent_index)) # Compute log odds ratio.
LSM_mats     <- Adj_Matrix_Construction(P_LSM)
P_LSM        <- LSM_mats$P_mat
A_LSM        <- LSM_mats$A_mat
# Next, conduct simulation for random dot product graph.
positions    <- sqrt(runif(N))
P_RDP        <- positions * t(replicate(N, positions))
RDP_mats     <- Adj_Matrix_Construction(P_RDP)
P_RDP        <- RDP_mats$P_mat
A_RDP        <- RDP_mats$A_mat
# Third, the stochastic block model simulation.
P_SBM        <- matrix(rep(0.3, N*N), nrow=N, ncol=N)
groups       <- 5
bs <- floor(N/5)
for (g in 0:(groups - 1)) {
P_SBM[(g * bs + 1):((g + 1) * bs), (g * bs + 1):((g + 1) * bs)] <- 0.7
}
SBM_mats     <- Adj_Matrix_Construction(P_SBM)
P_SBM        <- SBM_mats$P_mat
A_SBM        <- SBM_mats$A_mat
# Generate ARDs[]
types        <- matrix(rbinom(K*N, 1, 0.5), nrow = K, ncol = N)
ARD_LSM      <- t(types %*% A_LSM)
ARD_RDP      <- t(types %*% A_RDP)
ARD_SBM      <- t(types %*% A_SBM)
# Retrieve estimated matrices.
P_LSM.hat <- accel_nuclear_gradient(t(types), ARD_LSM, lambda=lambda)
P_RDP.hat <- accel_nuclear_gradient(t(types), ARD_RDP, lambda=lambda)
P_SBM.hat <- accel_nuclear_gradient(t(types), ARD_SBM, lambda=lambda)
MSE_LSM <- mean((P_LSM.hat - P_LSM)^2)
MSE_RDP <- mean((P_RDP.hat - P_RDP)^2)
MSE_SBM <- mean((P_SBM.hat - P_SBM)^2)
return(list(MSE_LSM = MSE_LSM, MSE_RDP = MSE_RDP, MSE_SBM = MSE_SBM))
}
simulation_outputs <- mclapply(1:R, function(x) MSE_simulation(x, lambda), mc.cores = num_cores)
simulation_outputs$MSE_LSM
simulation_outputs
simulation_outputs %>% unlist()
simulation_outputs %>% bind_rows()
# Next, run the simulations.
simulation_outputs <- mclapply(1:R, function(x) MSE_simulation(x, lambda), mc.cores = num_cores) %>%
bind_rows()
# Place simulation results into a dataframe.
MSE_df <- data.frame(model.type = c('LSM', 'RDP', 'SBM'),
MSE.vals = c(simulation_outputs$MSE_LSM, simulation_outputs$MSE_RDP, simulation_outputs$MSE_SBM),
lambda.vals = rep(lambda, 3))
R <- R_grid[R_index]
merged_MSE_df <- lapply(1:length(lambda_grid), parallel_simulations) %>%
bind_rows() %>%
mutate(K.vals = K) %>%
mutate(N.vals = N)
num_cores <- 15
merged_MSE_df <- lapply(1:10, parallel_simulations) %>%
bind_rows() %>%
mutate(K.vals = K) %>%
mutate(N.vals = N)
devtools::load_all('/users/halidaee/Dropbox/Ongoing Research/ARD_note/package/')
parallel::detectCores()
source('~/Dropbox/ARD/HossGridSearch/monte_carlo_local.R')
MSE_simulation(1, 1)
devtools::load_all('/users/halidaee/Dropbox/Ongoing Research/ARD_note/accelerated package/')
MSE_simulation(1, 1)
devtools::load_all('/users/halidaee/Dropbox/Ongoing Research/ARD_note/accelerated package/')
MSE_simulation(1, 1)
source('~/Dropbox/ARD/HossGridSearch/monte_carlo_local.R')
R <- 5
N <- 50
K <- 3
parallel_simulations(1)
merged_MSE_df <- lapply(1:10, parallel_simulations) %>%
bind_rows() %>%
mutate(K.vals = K) %>%
mutate(N.vals = N)
merged_MSE_list <- lapply(1:10, parallel_simulations)
lapply(1:10, print)
parallel_simulations(2)
parallel_simulations(3)
parallel_simulations(4)
parallel_simulations(5)
parallel_simulations(6)
parallel_simulations(7)
lambda_grid
merged_MSE_list <- lapply(1:min(10, length(lambda_grid))), parallel_simulations)
merged_MSE_df <- lapply(1:10, parallel_simulations) %>%
bind_rows() %>%
mutate(K.vals = K) %>%
mutate(N.vals = N)
merged_MSE_list <- lapply(1:min(c(10, length(lambda_grid)))), parallel_simulations)
merged_MSE_list <- lapply(1:min(c(10, length(lambda_grid))), parallel_simulations)
merged_MSE_df <- merged_MSE_list %>%
bind_rows() %>%
mutate(K.vals = K) %>%
mutate(N.vals = N)
ceiling
ceiling(sqrt(K)*N*4)
seq(50, ceiling(sqrt(K)*N*4), 50)
parallel_simulations <- function(lambda_index) {
# First, convert lambda index into an actual lambda.
lambda <- lambda_grid[lambda_index]
# Next, run the simulations.
simulation_outputs_list <- mclapply(1:R, function(x) MSE_simulation(x, lambda), mc.cores = num_cores)
simulation_outputs <- do.call("rbind", simulation_outputs_list)
# Place simulation results into a dataframe.
MSE_df <- data.frame(model.type = c('LSM', 'RDP', 'SBM'),
MSE.vals = c(simulation_outputs$MSE_LSM, simulation_outputs$MSE_RDP, simulation_outputs$MSE_SBM),
lambda.vals = rep(lambda, 3))
# Return the dataframe as output.
return(MSE_df)
}
parallel_simulations(1)
simulation_outputs_list <- mclapply(1:R, function(x) MSE_simulation(x, lambda_grid[1]), mc.cores = num_cores)
simulation_outputs <- do.call("rbind", simulation_outputs_list)
simulation_outputs
MSE_df <- data.frame(model.type = c('LSM', 'RDP', 'SBM'),
MSE.vals = c(simulation_outputs$MSE_LSM, simulation_outputs$MSE_RDP, simulation_outputs$MSE_SBM),
lambda.vals = rep(lambda, 3))
lambda <- lambda_grid[1]
MSE_df <- data.frame(model.type = c('LSM', 'RDP', 'SBM'),
MSE.vals = c(simulation_outputs$MSE_LSM, simulation_outputs$MSE_RDP, simulation_outputs$MSE_SBM),
lambda.vals = rep(lambda, 3))
c(simulation_outputs$MSE_LSM, simulation_outputs$MSE_RDP, simulation_outputs$MSE_SBM)
simulation_outputs
simulation_outputs$MSE_LSM
simulation_outputs %>% colnames()
simulation_outputs$MSE_LSM
class(simulation_outputs)
simulation_outputs <- data.frame(do.call("rbind", simulation_outputs_list))
MSE_df <- data.frame(model.type = c('LSM', 'RDP', 'SBM'),
MSE.vals = c(simulation_outputs$MSE_LSM, simulation_outputs$MSE_RDP, simulation_outputs$MSE_SBM),
lambda.vals = rep(lambda, 3))
MSE_df
View(MSE_df)
simulation_outputs
simulation_outputs$MSE_LSM
class(simulation_outputs)
class(simulation_outputs$MSE_LSM)
simulation_outputs <- as.data.frame(do.call("rbind", simulation_outputs_list))
simulation_outputs
simulation_outputs$MSE_LSM
simulation_outputs <-(do.call("rbind", simulation_outputs_list))
simulation_outputs
unlist(simulation_outputs)
simulation_outputs_list %>% unlist()
simulation_outputs_list %>% unlist() %>% data.frame()
simulation_outputs_list %>% unlist() %>% as.data.frame()
simulation_outputs_list %>% data.frame()
do.call("rbind", simulation_outputs_list %>% data.frame())
simulation_outputs_list[[1]]
simulation_outputs_list[[1]] %>% class()
library(nuclearARD)
library(nuclearARD)
## Set system parameters.
# Set seed for randomization.
set.seed(125)
# Define how many cores to use on each Quest node.
num_cores <- parallel::detectCores() - 1
# Pull job array index from Slurm. This will be used to determine which parameters are run on this node for our grid search.
job_array_index <- 1
## Define our grid. Further, to determine parameters easily from job_array_index, compute length of each dimension of grid.
# Number of individuals in the network.
N_grid        <- seq(50, 400, 50)
N_grid.length <- length(N_grid)
# Number of covariates used for ARD.
K_grid        <- seq(3, 12)
K_grid.length <- length(K_grid)
# Number of Monte Carlo simulations.
R_grid        <- seq(5, 10, 2)
R_grid.length <- length(R_grid)
# Grid for lambda is a function of K and N. Thus, it cannot be defined here. Must be defined after we know which (N, R, K)
# tuple this node is running.
## Define parameters for this node.
# Index for K is the top level index. Determine that first.
K_index                        <- floor(job_array_index/(N_grid.length * R_grid.length)) + 1
# Next is the R index. We need to "erase" the K index to back this out.
job_array_index.without_K      <- job_array_index - ((K_index - 1) * (N_grid.length * R_grid.length))
R_index                        <- floor(job_array_index.without_K/N_grid.length) + 1
# Index for N is just what remains of the index after subtracting everything else.
job_array_index.without_K_or_N <- job_array_index.without_K - ((R_index - 1) * N_grid.length)
N_index                        <- job_array_index.without_K_or_N
# Use these indices to pull the actual (N, R, K) combination to be evaluated.
#N <- N_grid[N_index]
#K <- K_grid[K_index]
#R <- R_grid[R_index]
R <- 5
N <- 800
K <- 3
# Now, we define the  upper limit for our bandwidth grid. We derived the analytical optimal bandwidth from Negahban and Wainwright,
# but think it is too conservative in practice. To find the actual optimal, we need to search over all bandwidth values below it.
lambda <- 2*(2*sqrt(N))*(sqrt(N) + sqrt(K))
alpha        <- rnorm(N) # Generate intercept term.
positions    <- matrix(rexp(N * 2), nrow=N, ncol=2) # Generate locations.
latent_index <- alpha + t(replicate(N, alpha)) - pdist(positions) # Compute latent index.
P_LSM        <- exp(latent_index) / (1 + exp(latent_index)) # Compute log odds ratio.
LSM_mats     <- Adj_Matrix_Construction(P_LSM)
P_LSM        <- LSM_mats$P_mat
A_LSM        <- LSM_mats$A_mat
# Next, conduct simulation for random dot product graph.
positions    <- sqrt(runif(N))
P_RDP        <- positions * t(replicate(N, positions))
RDP_mats     <- Adj_Matrix_Construction(P_RDP)
P_RDP        <- RDP_mats$P_mat
A_RDP        <- RDP_mats$A_mat
# Third, the stochastic block model simulation.
P_SBM        <- matrix(rep(0.3, N*N), nrow=N, ncol=N)
groups       <- 5
bs <- floor(N/5)
for (g in 0:(groups - 1)) {
P_SBM[(g * bs + 1):((g + 1) * bs), (g * bs + 1):((g + 1) * bs)] <- 0.7
}
SBM_mats     <- Adj_Matrix_Construction(P_SBM)
P_SBM        <- SBM_mats$P_mat
A_SBM        <- SBM_mats$A_mat
# Generate ARDs[]
types        <- matrix(rbinom(K*N, 1.0, 0.5), nrow = K, ncol = N)
ARD_LSM      <- types %*% A_LSM
ARD_RDP      <- types %*% A_RDP
ARD_SBM      <- types %*% A_SBM
Adj_Matrix_Construction <- function(P_mat) {
diag(P_mat) <- 0
U           <- matrix(runif(N*N), nrow=N, ncol=N)
U           <- t(U)/2 + U/2
A_mat       <- U < P_mat
return(list(P_mat = P_mat, A_mat = A_mat))
}
alpha        <- rnorm(N) # Generate intercept term.
positions    <- matrix(rexp(N * 2), nrow=N, ncol=2) # Generate locations.
latent_index <- alpha + t(replicate(N, alpha)) - pdist(positions) # Compute latent index.
P_LSM        <- exp(latent_index) / (1 + exp(latent_index)) # Compute log odds ratio.
LSM_mats     <- Adj_Matrix_Construction(P_LSM)
P_LSM        <- LSM_mats$P_mat
A_LSM        <- LSM_mats$A_mat
# Next, conduct simulation for random dot product graph.
positions    <- sqrt(runif(N))
P_RDP        <- positions * t(replicate(N, positions))
RDP_mats     <- Adj_Matrix_Construction(P_RDP)
P_RDP        <- RDP_mats$P_mat
A_RDP        <- RDP_mats$A_mat
# Third, the stochastic block model simulation.
P_SBM        <- matrix(rep(0.3, N*N), nrow=N, ncol=N)
groups       <- 5
bs <- floor(N/5)
for (g in 0:(groups - 1)) {
P_SBM[(g * bs + 1):((g + 1) * bs), (g * bs + 1):((g + 1) * bs)] <- 0.7
}
SBM_mats     <- Adj_Matrix_Construction(P_SBM)
P_SBM        <- SBM_mats$P_mat
A_SBM        <- SBM_mats$A_mat
# Generate ARDs[]
types        <- matrix(rbinom(K*N, 1.0, 0.5), nrow = K, ncol = N)
ARD_LSM      <- types %*% A_LSM
ARD_RDP      <- types %*% A_RDP
ARD_SBM      <- types %*% A_SBM
accel_nuclear_gradient(types, ARD_LSM, lambda=lambda)
library(rdist)
alpha        <- rnorm(N) # Generate intercept term.
positions    <- matrix(rexp(N * 2), nrow=N, ncol=2) # Generate locations.
latent_index <- alpha + t(replicate(N, alpha)) - pdist(positions) # Compute latent index.
P_LSM        <- exp(latent_index) / (1 + exp(latent_index)) # Compute log odds ratio.
LSM_mats     <- Adj_Matrix_Construction(P_LSM)
P_LSM        <- LSM_mats$P_mat
A_LSM        <- LSM_mats$A_mat
# Next, conduct simulation for random dot product graph.
positions    <- sqrt(runif(N))
P_RDP        <- positions * t(replicate(N, positions))
RDP_mats     <- Adj_Matrix_Construction(P_RDP)
P_RDP        <- RDP_mats$P_mat
A_RDP        <- RDP_mats$A_mat
# Third, the stochastic block model simulation.
P_SBM        <- matrix(rep(0.3, N*N), nrow=N, ncol=N)
groups       <- 5
bs <- floor(N/5)
for (g in 0:(groups - 1)) {
P_SBM[(g * bs + 1):((g + 1) * bs), (g * bs + 1):((g + 1) * bs)] <- 0.7
}
SBM_mats     <- Adj_Matrix_Construction(P_SBM)
P_SBM        <- SBM_mats$P_mat
A_SBM        <- SBM_mats$A_mat
# Generate ARDs[]
types        <- matrix(rbinom(K*N, 1.0, 0.5), nrow = K, ncol = N)
ARD_LSM      <- types %*% A_LSM
ARD_RDP      <- types %*% A_RDP
ARD_SBM      <- types %*% A_SBM
accel_nuclear_gradient(types, ARD_LSM, lambda=lambda)
library(nuclearARD)
install.packages('nuclearARD_0.1.tar.gz', repos=NULL, type='source') #Only needs to be run very first time
setwd("~/Dropbox/Projects/ARD/github_repository/R")
install.packages('nuclearARD_0.1.tar.gz', repos=NULL, type='source') #Only needs to be run very first time
R.Version()
packageVersion("Matrix")
install.packages("Matrix")
packageVersion("Matrix")
library(Matrix())
library(Matrix
)
install.packages(Matrix)
install.packages("Matrix")
library("Matrix")
install.packages("Matrix")
library("Matrix")
installed.packages("Matrix")
install.packages("Matrix")
librar("Matrix")
library("Matrix")
setwd("~/Dropbox/Projects/ARD/github_repository/R")
setwd("/private/var/folders/f1/tfkz7_y16t1dfwc0zv1r43vc0000gn/T/Rtmp3vz8e1/downloaded_packages")
library("Matrix")
install.packages("Matrix")
library("Matrix")
install.packages('nuclearARD_0.1.tar.gz', repos=NULL, type='source') #Only needs to be run very first time
library(nuclearARD)
set.seed(0) # set seed
N1 <- 100
N2 <- 200
K <- as.integer(round(N1^0.4))
# simulate network
positions <- sqrt(runif(N2))
M <- positions %*% t(positions) # n x n matrix of link probabilities
diag(M) <- 0 # zero out diagonal entries to ensure no self links
U <- matrix(runif(N2^2), nrow=N2, ncol=N2)
U <- t(U)/2 + U/2 # make matrix symmetric to have an undirected network
G <- (U < M)[,1:N1] # simulated network submatrix
types <- matrix(rbinom(K*N2, size=1, prob=0.5), nrow=K, ncol=N2)
ARDs <- types %*% G
write.csv(t(ARDs), 'ARD_data.csv')
write.csv(t(types), 'type_data.csv')
# load CSVs as numpy matrices
ARDs <- t(as.matrix(read.csv('ARD_data.csv')))
types <- t(as.matrix(read.csv('type_data.csv')))
# store dimensions
K <- nrow(ARDs)
N1 <- ncol(ARDs)
N2 <- ncol(types)
lmbd <- 2 * (sqrt(N1) + sqrt(N2)) * (sqrt(N2) + sqrt(K))
M_hat <- accel_nuclear_gradient(types, ARDs, lmbd)
#or just run
M_hat <- matrix_regression(types, ARDs)
print(M_hat[1:5, 1:5])
write.csv(as.matrix(M_hat), 'estimated_network.csv')
U <- matrix(runif(N2*N1), nrow=N2, ncol=N1) # draw uniform random variables
diag(U) <- 0 # zero out the diagonal entries (if no self links)
U_sub <- U[1:N1, ] # extract upper N1 x N1 submatrix
U_sub <- t(U_sub)/2 + U_sub # symmetrize the submatrix
U[1:N1, ] <- U_sub # replace the upper N1 x N1 submatrix of
#     the original matrix U with U_sub
G <- 1*(U < M_hat)
print(G[1:10, 1:10])
install.packages('nuclearARD_0.1.tar.gz', repos=NULL, type='source') #Only needs to be run very first time
setwd("~/Dropbox/Projects/ARD/github_repository/R")
install.packages('nuclearARD_0.1.tar.gz', repos=NULL, type='source') #Only needs to be run very first time
library(nuclearARD)
set.seed(0) # set seed
N1 <- 100
N2 <- 200
K <- as.integer(round(N1^0.4))
# simulate network
positions <- sqrt(runif(N2))
M <- positions %*% t(positions) # n x n matrix of link probabilities
diag(M) <- 0 # zero out diagonal entries to ensure no self links
U <- matrix(runif(N2^2), nrow=N2, ncol=N2)
U <- t(U)/2 + U/2 # make matrix symmetric to have an undirected network
G <- (U < M)[,1:N1] # simulated network submatrix
types <- matrix(rbinom(K*N2, size=1, prob=0.5), nrow=K, ncol=N2)
ARDs <- types %*% G
write.csv(t(ARDs), 'ARD_data.csv')
write.csv(t(types), 'type_data.csv')
# load CSVs as numpy matrices
ARDs <- t(as.matrix(read.csv('ARD_data.csv')))
types <- t(as.matrix(read.csv('type_data.csv')))
# store dimensions
K <- nrow(ARDs)
N1 <- ncol(ARDs)
N2 <- ncol(types)
lmbd <- 2 * (sqrt(N1) + sqrt(N2)) * (sqrt(N2) + sqrt(K))
M_hat <- accel_nuclear_gradient(types, ARDs, lmbd)
#or just run
M_hat <- matrix_regression(types, ARDs)
print(M_hat[1:5, 1:5])
write.csv(as.matrix(M_hat), 'estimated_network.csv')
U <- matrix(runif(N2*N1), nrow=N2, ncol=N1) # draw uniform random variables
diag(U) <- 0 # zero out the diagonal entries (if no self links)
U_sub <- U[1:N1, ] # extract upper N1 x N1 submatrix
U_sub <- t(U_sub)/2 + U_sub # symmetrize the submatrix
U[1:N1, ] <- U_sub # replace the upper N1 x N1 submatrix of
#     the original matrix U with U_sub
G <- 1*(U < M_hat)
print(G[1:10, 1:10])
set.seed(0) # set seed
N1 <- 100
N2 <- 200
K <- as.integer(round(N1^0.4))
# simulate network
positions <- sqrt(runif(N2))
M <- positions %*% t(positions) # n x n matrix of link probabilities
diag(M) <- 0 # zero out diagonal entries to ensure no self links
U <- matrix(runif(N2^2), nrow=N2, ncol=N2)
U <- t(U)/2 + U/2 # make matrix symmetric to have an undirected network
G <- (U < M)[,1:N1] # simulated network submatrix
print(G[1:10, 1:10])
types <- matrix(rbinom(K*N2, size=1, prob=0.5), nrow=K, ncol=N2)
ARDs <- types %*% G
write.csv(t(ARDs), 'ARD_data.csv')
write.csv(t(types), 'type_data.csv')
# load CSVs as numpy matrices
ARDs <- t(as.matrix(read.csv('ARD_data.csv')))
types <- t(as.matrix(read.csv('type_data.csv')))
# store dimensions
K <- nrow(ARDs)
N1 <- ncol(ARDs)
N2 <- ncol(types)
lmbd <- 2 * (sqrt(N1) + sqrt(N2)) * (sqrt(N2) + sqrt(K))
M_hat <- accel_nuclear_gradient(types, ARDs, lmbd)
#or just run
M_hat <- matrix_regression(types, ARDs)
print(M_hat[1:5, 1:5])
write.csv(as.matrix(M_hat), 'estimated_network.csv')
U <- matrix(runif(N2*N1), nrow=N2, ncol=N1) # draw uniform random variables
diag(U) <- 0 # zero out the diagonal entries (if no self links)
U_sub <- U[1:N1, ] # extract upper N1 x N1 submatrix
U_sub <- t(U_sub)/2 + U_sub # symmetrize the submatrix
U[1:N1, ] <- U_sub # replace the upper N1 x N1 submatrix of
#     the original matrix U with U_sub
G <- 1*(U < M_hat)
print(G[1:10, 1:10])
print(M[1:10, 1:10])
print(G[1:5, 1:5])
print(M[1:5, 1:5])
print(M_hat[1:5, 1:5])
cor(M,M_hat)
cor(as.vecotr(M),as.vector(M_hat))
cor(as.vector(M),as.vector(M_hat))
dim(M)
dim(M_hat)
print(M[1:5, 1:5])
print(M_hat[1:5, 1:5])
K
N1 <- 100
N2 <- 200
K <- as.integer(round(N1))
# simulate network
positions <- sqrt(runif(N2))
M <- positions %*% t(positions) # n x n matrix of link probabilities
diag(M) <- 0 # zero out diagonal entries to ensure no self links
U <- matrix(runif(N2^2), nrow=N2, ncol=N2)
U <- t(U)/2 + U/2 # make matrix symmetric to have an undirected network
G <- (U < M)[,1:N1] # simulated network submatrix
types <- matrix(rbinom(K*N2, size=1, prob=0.5), nrow=K, ncol=N2)
ARDs <- types %*% G
write.csv(t(ARDs), 'ARD_data.csv')
write.csv(t(types), 'type_data.csv')
# load CSVs as numpy matrices
ARDs <- t(as.matrix(read.csv('ARD_data.csv')))
types <- t(as.matrix(read.csv('type_data.csv')))
# store dimensions
K <- nrow(ARDs)
N1 <- ncol(ARDs)
N2 <- ncol(types)
lmbd <- 2 * (sqrt(N1) + sqrt(N2)) * (sqrt(N2) + sqrt(K))
M_hat <- accel_nuclear_gradient(types, ARDs, lmbd)
100^.4
100^.5
100^.9
N1 <- 100
N2 <- 200
K <- 20
# simulate network
positions <- sqrt(runif(N2))
M <- positions %*% t(positions) # n x n matrix of link probabilities
diag(M) <- 0 # zero out diagonal entries to ensure no self links
U <- matrix(runif(N2^2), nrow=N2, ncol=N2)
U <- t(U)/2 + U/2 # make matrix symmetric to have an undirected network
G <- (U < M)[,1:N1] # simulated network submatrix
types <- matrix(rbinom(K*N2, size=1, prob=0.5), nrow=K, ncol=N2)
ARDs <- types %*% G
write.csv(t(ARDs), 'ARD_data.csv')
write.csv(t(types), 'type_data.csv')
# load CSVs as numpy matrices
ARDs <- t(as.matrix(read.csv('ARD_data.csv')))
types <- t(as.matrix(read.csv('type_data.csv')))
# store dimensions
K <- nrow(ARDs)
N1 <- ncol(ARDs)
N2 <- ncol(types)
lmbd <- 2 * (sqrt(N1) + sqrt(N2)) * (sqrt(N2) + sqrt(K))
M_hat <- accel_nuclear_gradient(types, ARDs, lmbd)
#or just run
M_hat <- matrix_regression(types, ARDs)
print(M_hat[1:5, 1:5])
write.csv(as.matrix(M_hat), 'estimated_network.csv')
U <- matrix(runif(N2*N1), nrow=N2, ncol=N1) # draw uniform random variables
diag(U) <- 0 # zero out the diagonal entries (if no self links)
U_sub <- U[1:N1, ] # extract upper N1 x N1 submatrix
U_sub <- t(U_sub)/2 + U_sub # symmetrize the submatrix
U[1:N1, ] <- U_sub # replace the upper N1 x N1 submatrix of
#     the original matrix U with U_sub
G <- 1*(U < M_hat)
print(G[1:10, 1:10])
print(M[1:5, 1:5])
print(M_hat[1:5, 1:5])
print(G[1:10, 1:10])
