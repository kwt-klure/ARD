{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illustration of Alidaee, Auerbach, and Leung (2019)\n",
    "\n",
    "This notebook walks through a brief illustration of the penalized regression estimator of Alidaee, Auerbach, and Leung (2019) for recovering networks from ARD. Some interactive tutorials for Python, numpy, and the networkx module can be found [here](https://github.com/mpleung/Python_tutorials).\n",
    "\n",
    "The code blocks in this notebook can be changed if this notebook is opened in [nteract](https://nteract.io/desktop) or the following binder link:\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/mpleung/ARD/master?filepath=implementation_example.ipynb) \n",
    "\n",
    "Either method allows you to execute any Python code block by clicking on it and hitting *Shift+Enter*. These blocks can be modified by the user.\n",
    "\n",
    "## Background\n",
    "\n",
    "Let N2 be the number of agents in the full network, N1 the number of sample agents from which the researcher will gather ARD, and K the number of ARD questions of the form \"How many of your friends have type k?\" for k = 1, ..., K. Types could be characteristics like gender, race, or other such traits. The goal is to recover the N2 x N1 matrix $M^*$, which gives the linking probability between agents in the N1 sample and agents in the N2 population. \n",
    "\n",
    "The researcher conducts a full census of the network to obtain type data, which, in the example below, is stored in type\\_data.csv, a N2 x K matrix of indicators, where the ik-th entry is an indicator for whether agent i is type k. The ARD data is stored in ARD\\_data.csv, an N1 x K matrix where the ik-th entry is the number of agent i's friends of type k.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First we'll import the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, nuclear_norm_module as nn\n",
    "np.random.seed(0) # set seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*numpy* is a module for working with matrices in Python. \n",
    "\n",
    "*pandas* is a module only used here to load CSVs. \n",
    "\n",
    "*nuclear_norm_module* is our implementation of our estimator.\n",
    "\n",
    "### Simulate Data\n",
    "\n",
    "This section of the tutorial can be skipped. It is included only to show how the CSVs in our illustration were generated.\n",
    "\n",
    "Let *N1* be the number of units for which we obtain ARD. Let *N2* be the population size, meaning the number of units in the entire network. Let *K* be the number of traits for which we collect ARD.\n",
    "\n",
    "We simulate an undirected network with no self links from a random dot product graph on *N2* units. Then we take the submatrix of the network corresponding to links involving the subset of *N1* units for which we want to generate ARDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N1 = 100\n",
    "N2 = 200\n",
    "K = int(round(N1**(0.4)))\n",
    "\n",
    "# simulate network \n",
    "positions = np.sqrt(np.random.uniform(0,1,N2))\n",
    "M = positions * positions[:,None] # n x n matrix of link probabilities\n",
    "np.fill_diagonal(M,0) # zero out diagonal entries to ensure no self links\n",
    "U = np.random.uniform(0,1,size=(N2,N2))\n",
    "U = U.T/2 + U/2 # make matrix symmetric to have an undirected network\n",
    "G = (U < M)[:,:N1] # simulated network submatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we discuss below how to use the result of our estimation procedure, we explain some of these commands used to simulate the network.\n",
    "\n",
    "Next we create a *K* by *N2* matrix of types, which we'll just take to be a matrix of i.i.d. Bernoulli random variables. Call this matrix *types*. Then we'll construct the ARDs, which is what the econometrician actually observes in data. This is obtained just by taking the matrix product of *types* and *G*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = np.random.binomial(1,0.5,size=(K,N2))\n",
    "ARDs = types.dot(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In preparation for the actual exercise, we next save these matrices in CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ARDs.T).to_csv('ARD_data.csv', index=False, header=False)\n",
    "pd.DataFrame(types.T).to_csv('type_data.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This saves *ARDs* in a file *ARD_data.csv* and *types* in a file *type_data.csv*.\n",
    "\n",
    "### Load Data\n",
    "\n",
    "In the previous section, we simulated the following numpy matrices, which we saved as CSVs.\n",
    "\n",
    "*types* is a K by N2 matrix of indicators giving the types of each unit in the surveyed population. For example, the first column might contain indicators for being female, being white, etc. for unit 1.\n",
    "\n",
    "*ARDs* is a K by N1 matrix of K ARDs for N1 observations. For example, the first column might contain the number of female friends, number of white friends, etc. of unit 1.\n",
    "\n",
    "In practice, we would have gathered this data from the field and have them already saved in CSVs. We load them as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load CSVs as numpy matrices\n",
    "ARDs = pd.read_csv('ARD_data.csv', header=None).values.T\n",
    "types = pd.read_csv('type_data.csv', header=None).values.T\n",
    "\n",
    "# store dimensions\n",
    "K = ARDs.shape[0]\n",
    "N1 = ARDs.shape[1]\n",
    "N2 = types.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation\n",
    "\n",
    "To estimate the distribution of the network, we use the function *matrix_regression* in *nuclear_norm_module*, the latter of which we have already imported under the abbreviation *nn*.\n",
    "\n",
    "Note: the code snippet below might take a beat to run in binder, but it is fast on a personal computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmbd = 2 * (np.sqrt(N1) + np.sqrt(N2)) * (np.sqrt(N2) + np.sqrt(K))\n",
    "M_hat = nn.matrix_regression(ARDs, types, lmbd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*lmbd* is the penalty parameter, which follows the recommendation in our paper.\n",
    "\n",
    "*M_hat* is our main estimate. It is an N2 by N1 matrix, where the *ij*th entry is our estimate of the probability that unit *i* links with unit *j*.\n",
    "\n",
    "Just to see that we've done something, let's print the upper 5 by 5 submatrix of *M_hat*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.51647246 0.47357756 0.47329092 0.37561818]\n",
      " [0.51647246 0.         0.54723299 0.54670884 0.43382972]\n",
      " [0.47357756 0.54723299 0.         0.50109015 0.39798795]\n",
      " [0.47329092 0.54670884 0.50109015 0.         0.39760815]\n",
      " [0.37561818 0.43382972 0.39798795 0.39760815 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(M_hat[0:5,0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Result\n",
    "\n",
    "The estimated network distribution *M_hat* can be saved in a CSV as follows. It can then be imported into the user's favorite statistical computing environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save in a CSV file called estimated_network\n",
    "pd.DataFrame(M_hat).to_csv('estimated_network.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result can then be used as an input into a second-stage model. See Breza et al. (2019) for possible applications.\n",
    "\n",
    "It may also be of interest to simulate networks from *M_hat*. In our model, *M_hat* (or more precisely its upper diagonal, given the network is undirected) is a matrix of independent linking probabilities. Thus to simulate a network *G* from *M_hat*, we just draw an N2 by N1 matrix of i.i.d. uniform random variables, denoted by *U* and form the *ij* entry of *G* according to $G_{ij}=\\mathbf{1}\\{U_{ij} < \\hat{M}_{ij}\\}$. In Python, this is done as follows.\n",
    "\n",
    "First, draw an N2 by N1 matrix of i.i.d. uniform random variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = np.random.uniform(0,1,size=(N2,N1)) # draw uniform random variables\n",
    "np.fill_diagonal(U,0)                   # zero out the diagonal entries (if no self links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the true network is undirected, then we need to symmetrize the upper N1 by N1 submatrix. If the true matrix is directed, then skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_sub = U[:N1,:]            # extract upper N1 x N1 submatrix\n",
    "U_sub = U_sub.T/2 + U_sub/2 # symmetrize the submatrix\n",
    "U[:N1,:] = U_sub            # replace the upper N1 x N1 submatrix of\n",
    "                            #     the original matrix U with U_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given *U* and *M_hat*, our simulated network *G* is obtained as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = (U < M_hat).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command *(U < M_hat)* generates an N2 x N1 matrix of booleans (True/False) where the *ij*th entry is True if and only if $U_{ij} < \\hat{M}_{ij}$. To convert this to 1s and 0s, we use the *astype* method to convert to the integer type.\n",
    "\n",
    "Now we can use *G* as an input into some second stage procedure. See Breza et al. (2019) for examples. Just to see that we've done something, let's print the upper 10 x 10 submatrix of *G*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 1 0 1 0]\n",
      " [0 0 0 0 0 0 1 1 1 1]\n",
      " [0 0 0 0 0 0 1 0 1 0]\n",
      " [0 0 0 0 0 1 0 1 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 1 1 0]\n",
      " [1 1 1 0 0 0 0 1 0 0]\n",
      " [0 1 0 1 0 1 1 0 1 0]\n",
      " [1 1 1 1 0 1 0 1 0 1]\n",
      " [0 1 0 0 0 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(G[0:10,0:10])"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
